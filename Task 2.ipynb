{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee6313e",
   "metadata": {},
   "source": [
    "## Task 2 \n",
    "#### Track a specific vehicle in a given video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f2d238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbfea445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required files paths \n",
    "Train_Mode = False\n",
    "\n",
    "if Train_Mode:\n",
    "    videos = r'D:\\Uni_Buc\\Uni_Buc_semester_2\\Computer Vision\\CV 2023\\CV-2023-Project2\\train\\Task2\\*.mp4'\n",
    "    bounding_boxes = r'D:\\Uni_Buc\\Uni_Buc_semester_2\\Computer Vision\\CV 2023\\CV-2023-Project2\\train\\Task2\\*.txt'\n",
    "else:\n",
    "    videos = r'D:\\Uni_Buc\\Uni_Buc_semester_2\\Computer Vision\\CV 2023\\CV-2023-Project2\\test\\Task2\\*.mp4'\n",
    "    bounding_boxes = r'D:\\Uni_Buc\\Uni_Buc_semester_2\\Computer Vision\\CV 2023\\CV-2023-Project2\\test\\Task2\\*.txt'\n",
    "    \n",
    "videos_paths = sorted(glob.glob(videos), key=lambda i: int(os.path.splitext(os.path.basename(i))[0]))\n",
    "boxes_paths = sorted(glob.glob(bounding_boxes), key=lambda i: int(os.path.splitext(os.path.basename(i))[0]))\n",
    "\n",
    "results_paths = r'D:\\Uni_Buc\\Uni_Buc_semester_2\\Computer Vision\\CV 2023\\CV-2023-Project2\\Lara_Tomeh_507\\Task2'\n",
    "ground_truth_paths = r'D:\\Uni_Buc\\Uni_Buc_semester_2\\Computer Vision\\CV 2023\\CV-2023-Project2\\train\\Task2\\ground-truth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Different types of Python open cv trackers\n",
    "# tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "# tracker_type = tracker_types[0]\n",
    "# if tracker_type == 'BOOSTING':\n",
    "#     tracker = cv2.legacy.TrackerBoosting_create()\n",
    "# if tracker_type == 'MIL':\n",
    "#     tracker = cv2.TrackerMIL_create() \n",
    "# if tracker_type == 'KCF':\n",
    "#     tracker = cv2.TrackerKCF_create() \n",
    "# if tracker_type == 'TLD':\n",
    "#     tracker = cv2.legacy.TrackerTLD_create() \n",
    "# if tracker_type == 'MEDIANFLOW':\n",
    "#     tracker = cv2.legacy.TrackerMedianFlow_create() \n",
    "# # if tracker_type == 'GOTURN':\n",
    "# #     tracker = cv2.TrackerGOTURN_create()\n",
    "# if tracker_type == 'MOSSE':\n",
    "#     tracker = cv2.legacy.TrackerMOSSE_create()\n",
    "# if tracker_type == \"CSRT\":\n",
    "#     tracker = cv2.TrackerCSRT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d19504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the actual bounding boxes\n",
    "def bbox():\n",
    "    all_bboxes = []\n",
    "    all_frames = []\n",
    "    for i, box in enumerate(boxes_paths):\n",
    "        with open(box) as f:\n",
    "            frames = int(f.readline().split(' ')[0])\n",
    "            all_frames.append(frames)\n",
    "            _, x1, y1, x2, y2 = f.readline().split()[:5]\n",
    "            all_bboxes.append([int(x1), int(y1), int(x2), int(y2)])\n",
    "            \n",
    "    return all_frames, all_bboxes\n",
    "\n",
    "all_frames, all_bboxes = bbox()\n",
    "\n",
    "# Create the predicted bounding boxes dictionary\n",
    "predicted_bboxes = {}\n",
    "for i, video_path in enumerate(videos_paths, start=1):\n",
    "    predicted_bboxes[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140a30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tracking\n",
    "for i in range(0, 15): # 15 is the total videos\n",
    "    \n",
    "    # Create an object of Python Tracker\n",
    "    tracker = cv2.legacy.TrackerBoosting_create()\n",
    "    \n",
    "    # Initialize frame_number\n",
    "    frame_number = 0 \n",
    "    \n",
    "    # Get the video file and read it   \n",
    "    video = cv2.VideoCapture(videos_paths[i])\n",
    "    \n",
    "    # Read the first frame\n",
    "    _, frame = video.read() \n",
    "\n",
    "    # We perform this subtraction to get the width and height from (xmin,ymin) & (xmax,ymax), top_left & bottom_right points\n",
    "    [x, y, w, h] = all_bboxes[i]  \n",
    "    bbox = (x, y, w-x, h-y)  \n",
    "\n",
    "    # Append first bounding box to the list\n",
    "    predicted_bboxes[i + 1].append([frame_number, int(bbox[0]), int(bbox[1]), int(bbox[0]) + int(bbox[2]), int(bbox[1]) + int(bbox[3])])\n",
    "\n",
    "    # If we want to select the bounding box manually\n",
    "    # bbox = cv2.selectROI(frame, False)\n",
    "    \n",
    "    # Initialize the tracker\n",
    "    tracker.init(frame, bbox)  \n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "#             print('ERROR!')\n",
    "            break\n",
    "            \n",
    "        frame_number += 1\n",
    "        \n",
    "        # Update the tracker\n",
    "        ret, bbox = tracker.update(frame)  \n",
    "        \n",
    "        if ret:\n",
    "            # Draw a rectangle surrounding the object\n",
    "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3])), (255, 255, 255), 2, 1)\n",
    "        \n",
    "        # Add the actual bounding box to the list\n",
    "        predicted_bboxes[i + 1].append([frame_number, int(bbox[0]), int(bbox[1]), int(bbox[0]) + int(bbox[2]), int(bbox[1]) + int(bbox[3])])\n",
    "\n",
    "        # Open the file and write the content (bounding boxes' coordinations)\n",
    "        for k, v in predicted_bboxes.items():\n",
    "            if not os.path.exists(results_paths):\n",
    "                os.makedirs(results_paths)\n",
    "            file_num = ''\n",
    "            number = k\n",
    "            if number < 10:\n",
    "                file_num = '0' + str(number)\n",
    "            else:\n",
    "                file_num = str(number)\n",
    "            f = open(results_paths + '/' + file_num + '_predicted.txt', 'w')\n",
    "            f.write(str(all_frames[k - 1]) + ' -1 -1 -1 -1\\n')\n",
    "            for [a, x, y, w, h] in v:\n",
    "                f.write(str(a) + ' ' + str(x) + ' ' + str(y) + ' ' + str(w) + ' ' + str(h) + '\\n')\n",
    "            f.close()\n",
    "          \n",
    "          # In case we want to show the tracking frame\n",
    "#         cv2.imshow(\"Tracking objects\", frame)\n",
    "#         k = cv2.waitKey(1) & 0xff\n",
    "#         if k == 27 :\n",
    "#             break\n",
    "\n",
    "video.release()       \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeed117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "def compute_percentage_tracking(gt_bboxes, predicted_bboxes, num_frames,verbose=0):\n",
    "    \"\"\"\n",
    "    This function compute the percentage of detected bounding boxes based on the ground-truth bboxes and the predicted ones.\n",
    "    :param gt_bboxes. The ground-truth bboxes with the format: frame_idx, x_min, y_min, x_max, y_max.\n",
    "    :param predicted_bboxes. The predicted bboxes with the format: frame_idx, x_min, y_min, x_max, y_max\n",
    "    :param num_frames. The total number of frames in the video.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_frames = int(num_frames)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    gt_dict = {}\n",
    "    for gt_box in gt_bboxes:\n",
    "        gt_dict[gt_box[0]] = gt_box[1:]\n",
    "    \n",
    "    pred_dict = {}\n",
    "    for pred_bbox in predicted_bboxes:\n",
    "        pred_dict[pred_bbox[0]] = pred_bbox[1:]\n",
    "        \n",
    "    for i in range(num_frames):\n",
    "        if gt_dict.get(i, None) is None and pred_dict.get(i, None) is None: # the bowling bowl is not on the lane\n",
    "            tn += 1 \n",
    "        \n",
    "        elif gt_dict.get(i, None) is not None and pred_dict.get(i, None) is None: # the bowling ball is not detected\n",
    "            fn += 1\n",
    "            \n",
    "        elif gt_dict.get(i, None) is None and pred_dict.get(i, None) is not None: # the bowling ball is not on the lane, but it is 'detected'\n",
    "            fp += 1\n",
    "            \n",
    "        elif gt_dict.get(i, None) is not None and pred_dict.get(i, None) is not None: # the bowling ball is on the lane and it is detected\n",
    "            \n",
    "            iou = bb_intersection_over_union(gt_dict[i], pred_dict[i])\n",
    "            if iou >= 0.2:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1 \n",
    "                         \n",
    "    if verbose:\n",
    "        print(f'tp = {tp}, tn = {tn}, fp = {fp},fn = {fn}')\n",
    "    assert tn + fn + tp + fp == num_frames\n",
    "    perc = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    return perc\n",
    "\n",
    "def evaluate_results_task2(predictions_path,ground_truth_path, verbose = 0):\n",
    "    total_correct_tracked_videos = 0\n",
    "    for i in range(1,16):\n",
    "\n",
    "        correct_tracked_video = 0\n",
    "    \n",
    "        try:\n",
    "\n",
    "            if(i<10):\n",
    "                name = '0' + str(i)\n",
    "            else:\n",
    "                name = str(i)\n",
    "    \n",
    "            filename_predictions = predictions_path + \"/\" + name + \"_predicted.txt\"\n",
    "            filename_ground_truth = ground_truth_path + \"/\" + name + \"_gt.txt\"\n",
    "\n",
    "            p = np.loadtxt(filename_predictions)   \n",
    "            predicted_bboxes = p[1:]\n",
    "            gt = np.loadtxt(filename_ground_truth)\n",
    "            gt_bboxes = gt[1:]\n",
    "            num_frames = gt[0][0]\n",
    "            percentage = compute_percentage_tracking(gt_bboxes, predicted_bboxes, num_frames,verbose)\n",
    "\n",
    "            correct_tracked_video = 1\n",
    "            if percentage < 0.8:\n",
    "                correct_tracked_video = 0\n",
    "                print(i)  \n",
    "            else:\n",
    "                print(percentage)\n",
    "        \n",
    "    \n",
    "            if verbose:\n",
    "                print(\"percentage = \", percentage)\n",
    "                print(\"Task 2 - Tracking the vehicle: for test example number \", str(i), \" the prediction is :\", (1-correct_tracked_video) * \"in\" + \"correct\", \"\\n\")\n",
    "        \n",
    "            total_correct_tracked_videos = total_correct_tracked_videos + correct_tracked_video\n",
    "    \n",
    "        except:\n",
    "            print(\"Error\")\n",
    "\n",
    "        points = total_correct_tracked_videos * 0.1\n",
    "        \n",
    "    return total_correct_tracked_videos,points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e16c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate_results_task2(results_paths, ground_truth_paths, verbose = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cca2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
